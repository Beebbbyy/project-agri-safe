# Project Agri-Safe - Makefile
# Convenience commands for managing Docker services

.PHONY: help setup up down restart logs status clean test db-connect redis-connect airflow-restart

# Default target
help:
	@echo "ğŸŒ¾ Project Agri-Safe - Available Commands"
	@echo ""
	@echo "Setup & Start:"
	@echo "  make setup          - Initial setup (copy .env, create dirs)"
	@echo "  make up             - Start all services"
	@echo "  make down           - Stop all services"
	@echo ""
	@echo "Management:"
	@echo "  make restart        - Restart all services"
	@echo "  make logs           - View all logs (follow mode)"
	@echo "  make status         - Check service status"
	@echo ""
	@echo "Database:"
	@echo "  make db-connect     - Connect to PostgreSQL"
	@echo "  make db-reset       - Reset database (DANGER!)"
	@echo "  make db-backup      - Backup database"
	@echo "  make db-migrate-phase3 - Run Phase 3 migrations"
	@echo ""
	@echo "Redis:"
	@echo "  make redis-connect  - Connect to Redis CLI"
	@echo ""
	@echo "Airflow:"
	@echo "  make airflow-restart - Restart Airflow services"
	@echo "  make airflow-logs   - View Airflow logs"
	@echo "  make list-dags      - List Phase 3 DAGs"
	@echo "  make trigger-etl    - Trigger weather ETL"
	@echo "  make trigger-predictions - Trigger predictions"
	@echo ""
	@echo "Phase 3 - Spark:"
	@echo "  make spark-up       - Start Spark cluster"
	@echo "  make spark-down     - Stop Spark cluster"
	@echo "  make spark-logs     - View Spark logs"
	@echo "  make spark-status   - Check Spark status"
	@echo ""
	@echo "Phase 3 - ETL & Processing:"
	@echo "  make run-etl        - Run weather ETL pipeline"
	@echo "  make run-features   - Generate rolling features"
	@echo ""
	@echo "Phase 3 - ML Models:"
	@echo "  make train-model    - Train flood risk model"
	@echo "  make run-predictions - Generate predictions"
	@echo "  make test-model-v1  - Test rule-based model"
	@echo "  make test-model-v2  - Test ML model"
	@echo ""
	@echo "Phase 3 - Data Quality:"
	@echo "  make quality-checks - Run quality validation"
	@echo "  make quality-report - Generate quality report"
	@echo ""
	@echo "Phase 3 - Quick Start:"
	@echo "  make phase3-setup   - Setup Phase 3 infrastructure"
	@echo "  make phase3-init    - Full Phase 3 initialization"
	@echo "  make phase3-status  - Check Phase 3 status"
	@echo ""
	@echo "Cleanup:"
	@echo "  make clean          - Stop and remove containers"
	@echo "  make clean-all      - Remove everything including volumes (DANGER!)"
	@echo ""
	@echo "Development:"
	@echo "  make test           - Run tests"
	@echo "  make test-phase3    - Run Phase 3 tests"
	@echo "  make lint           - Run linters"
	@echo ""

# Initial setup
setup:
	@echo "ğŸ”§ Setting up Project Agri-Safe..."
	@if [ ! -f .env ]; then \
		cp .env.example .env; \
		echo "âœ… Created .env file from .env.example"; \
	else \
		echo "â„¹ï¸  .env file already exists"; \
	fi
	@mkdir -p airflow/{dags,logs,plugins}
	@mkdir -p data/{raw,processed}
	@mkdir -p backend/{app,tests}
	@mkdir -p frontend
	@mkdir -p sql/{schema,migrations,seeds}
	@mkdir -p docker docs
	@echo "âœ… Directories created"
	@if [ "$(shell uname)" != "Darwin" ] && [ "$(shell uname)" != "Windows" ]; then \
		if ! grep -q "AIRFLOW_UID" .env; then \
			echo "AIRFLOW_UID=$(shell id -u)" >> .env; \
			echo "âœ… Added AIRFLOW_UID to .env"; \
		fi; \
	fi
	@echo "âœ… Setup complete! Run 'make up' to start services."

# Start all services
up:
	@echo "ğŸš€ Starting all services..."
	docker compose up -d
	@echo "â³ Waiting for services to be healthy..."
	@sleep 10
	@echo "âœ… Services started!"
	@echo ""
	@echo "ğŸ“Š Access services at:"
	@echo "  - Airflow UI: http://localhost:8080 (admin/admin)"
	@echo "  - PostgreSQL: localhost:5432 (agrisafe/agrisafe_password)"
	@echo "  - Redis: localhost:6379"

# Stop all services
down:
	@echo "ğŸ›‘ Stopping all services..."
	docker compose down
	@echo "âœ… Services stopped"

# Restart all services
restart:
	@echo "ğŸ”„ Restarting all services..."
	docker compose restart
	@echo "âœ… Services restarted"

# View logs
logs:
	docker compose logs -f

# Check service status
status:
	@echo "ğŸ“Š Service Status:"
	@docker compose ps

# Clean up containers
clean:
	@echo "ğŸ§¹ Cleaning up containers..."
	docker compose down
	@echo "âœ… Cleanup complete"

# Clean everything including volumes (DANGER!)
clean-all:
	@echo "âš ï¸  WARNING: This will delete all data!"
	@read -p "Are you sure? (yes/no): " confirm; \
	if [ "$$confirm" = "yes" ]; then \
		docker compose down -v; \
		echo "âœ… All data removed"; \
	else \
		echo "âŒ Cancelled"; \
	fi

# Connect to PostgreSQL
db-connect:
	@echo "ğŸ—„ï¸  Connecting to PostgreSQL..."
	docker exec -it agrisafe-postgres psql -U agrisafe -d agrisafe_db

# Reset database (DANGER!)
db-reset:
	@echo "âš ï¸  WARNING: This will reset the database!"
	@read -p "Are you sure? (yes/no): " confirm; \
	if [ "$$confirm" = "yes" ]; then \
		docker compose down; \
		docker volume rm project-agri-safe_postgres_data || true; \
		docker compose up -d postgres; \
		echo "âœ… Database reset complete"; \
	else \
		echo "âŒ Cancelled"; \
	fi

# Backup database
db-backup:
	@echo "ğŸ’¾ Backing up database..."
	@mkdir -p backups
	docker exec agrisafe-postgres pg_dump -U agrisafe agrisafe_db > backups/backup_$(shell date +%Y%m%d_%H%M%S).sql
	@echo "âœ… Backup created in backups/"

# Connect to Redis
redis-connect:
	@echo "ğŸ“¦ Connecting to Redis..."
	docker exec -it agrisafe-redis redis-cli

# Restart Airflow services
airflow-restart:
	@echo "ğŸ”„ Restarting Airflow services..."
	docker compose restart airflow-webserver airflow-scheduler airflow-worker
	@echo "âœ… Airflow restarted"

# View Airflow logs
airflow-logs:
	docker compose logs -f airflow-webserver airflow-scheduler airflow-worker

# Run tests (placeholder for future)
test:
	@echo "ğŸ§ª Running tests..."
	@echo "âš ï¸  Tests not yet implemented (Phase 6)"

# Run linters (placeholder for future)
lint:
	@echo "ğŸ” Running linters..."
	@echo "âš ï¸  Linting not yet configured (Phase 4)"

# ============================================================================
# PHASE 3 COMMANDS: Data Processing & ML
# ============================================================================

# Spark services
.PHONY: spark-up spark-down spark-logs spark-status

spark-up:
	@echo "âš¡ Starting Spark services..."
	docker compose up -d spark-master spark-worker
	@sleep 5
	@echo "âœ… Spark services started!"
	@echo "  - Spark Master UI: http://localhost:8081"
	@echo "  - Spark Worker UI: http://localhost:8083"
	@echo "  - Spark Application UI: http://localhost:4040 (when job running)"

spark-down:
	@echo "ğŸ›‘ Stopping Spark services..."
	docker compose stop spark-master spark-worker
	@echo "âœ… Spark stopped"

spark-logs:
	@echo "ğŸ“œ Spark logs:"
	docker compose logs -f spark-master spark-worker

spark-status:
	@echo "ğŸ“Š Spark Status:"
	@docker compose ps spark-master spark-worker

# Database migrations
.PHONY: db-migrate-phase3

db-migrate-phase3:
	@echo "ğŸ—„ï¸  Running Phase 3 database migrations..."
	docker exec -i agrisafe-postgres psql -U agrisafe -d agrisafe_db < sql/migrations/03_phase3_tables.sql
	@echo "âœ… Phase 3 tables created!"

# ETL Jobs
.PHONY: run-etl run-features

run-etl:
	@echo "âš™ï¸  Running weather ETL pipeline..."
	docker exec agrisafe-airflow-worker python -m src.processing.spark_jobs.weather_etl \
		--start-date $(shell date -d '30 days ago' +%Y-%m-%d) \
		--end-date $(shell date +%Y-%m-%d)

run-features:
	@echo "ğŸ”§ Generating rolling features..."
	docker exec agrisafe-airflow-worker python -m src.processing.spark_jobs.rolling_features \
		--start-date $(shell date -d '30 days ago' +%Y-%m-%d) \
		--end-date $(shell date +%Y-%m-%d)

# ML Model commands
.PHONY: train-model run-predictions test-model-v1 test-model-v2

train-model:
	@echo "ğŸ¤– Training flood risk model..."
	docker exec agrisafe-airflow-worker python -m src.models.training_pipeline \
		--days 180 \
		--test-size 0.2
	@echo "âœ… Model training complete! Check models/ directory"

run-predictions:
	@echo "ğŸ”® Generating flood risk predictions..."
	docker exec agrisafe-airflow-worker python -m src.models.batch_predictions \
		--date $(shell date +%Y-%m-%d) \
		--model-version v2
	@echo "âœ… Predictions generated for all regions"

test-model-v1:
	@echo "ğŸ§ª Testing rule-based model (v1)..."
	docker exec agrisafe-airflow-worker python -c "\
from src.models.flood_risk_v1 import RuleBasedFloodModel; \
model = RuleBasedFloodModel(); \
features = {'rainfall_1d': 120, 'rainfall_7d': 300, 'elevation': 50, 'historical_flood_count': 3}; \
result = model.predict(features); \
print(f'Risk Level: {result.risk_level}'); \
print(f'Confidence: {result.confidence_score:.2f}'); \
print(f'Recommendation: {result.recommendation}'); \
"

test-model-v2:
	@echo "ğŸ§ª Testing ML-based model (v2)..."
	@echo "âš ï¸  Ensure model is trained first with 'make train-model'"
	docker exec agrisafe-airflow-worker python -m src.models.batch_predictions --date $(shell date +%Y-%m-%d) --model-version v2

# Data Quality commands
.PHONY: quality-checks quality-report quality-dashboard

quality-checks:
	@echo "âœ… Running data quality checks..."
	docker exec agrisafe-airflow-worker python -m src.quality.validators
	@echo "âœ… Quality checks complete"

quality-report:
	@echo "ğŸ“Š Generating quality report..."
	docker exec agrisafe-airflow-worker python -m src.quality.monitoring
	@echo "âœ… Report generated"

quality-dashboard:
	@echo "ğŸ“ˆ Opening quality dashboard..."
	@echo "âš ï¸  Dashboard feature coming in Phase 5"

# Airflow DAG management
.PHONY: trigger-etl trigger-predictions trigger-quality trigger-training list-dags

list-dags:
	@echo "ğŸ“‹ Available Airflow DAGs:"
	docker exec agrisafe-airflow-webserver airflow dags list | grep -E "(weather|flood|quality)"

trigger-etl:
	@echo "â–¶ï¸  Triggering weather ETL DAG..."
	docker exec agrisafe-airflow-webserver airflow dags trigger weather_data_processing
	@echo "âœ… DAG triggered! Check Airflow UI: http://localhost:8080"

trigger-predictions:
	@echo "â–¶ï¸  Triggering flood predictions DAG..."
	docker exec agrisafe-airflow-webserver airflow dags trigger flood_risk_predictions
	@echo "âœ… DAG triggered! Check Airflow UI: http://localhost:8080"

trigger-quality:
	@echo "â–¶ï¸  Triggering data quality DAG..."
	docker exec agrisafe-airflow-webserver airflow dags trigger data_quality_monitoring
	@echo "âœ… DAG triggered! Check Airflow UI: http://localhost:8080"

trigger-training:
	@echo "â–¶ï¸  Triggering model training DAG..."
	docker exec agrisafe-airflow-webserver airflow dags trigger flood_model_training
	@echo "âœ… DAG triggered! Check Airflow UI: http://localhost:8080"

# Phase 3 testing
.PHONY: test-phase3 test-phase3-integration

test-phase3:
	@echo "ğŸ§ª Running Phase 3 unit tests..."
	docker exec agrisafe-airflow-worker pytest tests/processing tests/models tests/quality -v --cov
	@echo "âœ… Tests complete"

test-phase3-integration:
	@echo "ğŸ§ª Running Phase 3 integration tests..."
	docker exec agrisafe-airflow-worker pytest tests/integration/test_phase3.py -v
	@echo "âœ… Integration tests complete"

# Phase 3 complete setup
.PHONY: phase3-setup phase3-init phase3-status

phase3-setup: spark-up db-migrate-phase3
	@echo "ğŸ‰ Phase 3 infrastructure ready!"
	@echo ""
	@echo "Next steps:"
	@echo "  1. Run 'make run-etl' to process weather data"
	@echo "  2. Run 'make train-model' to train ML model"
	@echo "  3. Run 'make run-predictions' to generate predictions"
	@echo "  4. Run 'make quality-checks' to validate data"

phase3-init: phase3-setup run-etl train-model run-predictions
	@echo "ğŸš€ Phase 3 fully initialized with sample data!"

phase3-status:
	@echo "ğŸ“Š Phase 3 Status Check"
	@echo ""
	@echo "Spark Services:"
	@docker compose ps spark-master spark-worker
	@echo ""
	@echo "Database Tables:"
	@docker exec agrisafe-postgres psql -U agrisafe -d agrisafe_db -c "\dt weather_daily_stats" 2>/dev/null || echo "âŒ weather_daily_stats not found"
	@docker exec agrisafe-postgres psql -U agrisafe -d agrisafe_db -c "\dt feature_store" 2>/dev/null || echo "âŒ feature_store not found"
	@docker exec agrisafe-postgres psql -U agrisafe -d agrisafe_db -c "\dt data_quality_checks" 2>/dev/null || echo "âŒ data_quality_checks not found"
	@echo ""
	@echo "Models:"
	@ls -lh models/*.pkl 2>/dev/null || echo "âŒ No trained models found"
	@echo ""
	@echo "Airflow DAGs:"
	@docker exec agrisafe-airflow-webserver airflow dags list 2>/dev/null | grep -E "(weather|flood|quality)" || echo "âŒ Phase 3 DAGs not loaded"

# ============================================================================
# END PHASE 3 COMMANDS
# ============================================================================

# Development helpers
dev-setup: setup up
	@echo "ğŸ‰ Development environment ready!"

# Health check
health:
	@echo "ğŸ¥ Running health checks..."
	@echo ""
	@echo "PostgreSQL:"
	@docker exec agrisafe-postgres pg_isready -U agrisafe || echo "âŒ PostgreSQL not ready"
	@echo ""
	@echo "Redis:"
	@docker exec agrisafe-redis redis-cli ping || echo "âŒ Redis not ready"
	@echo ""
	@echo "Airflow:"
	@curl -s http://localhost:8080/health > /dev/null && echo "âœ… Airflow webserver is healthy" || echo "âŒ Airflow not ready"

# Show environment info
info:
	@echo "ğŸ“‹ Environment Information"
	@echo ""
	@echo "Docker version:"
	@docker --version
	@echo ""
	@echo "Docker Compose version:"
	@docker compose version
	@echo ""
	@echo "Running containers:"
	@docker compose ps
